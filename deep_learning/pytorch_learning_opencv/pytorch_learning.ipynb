{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "print(\"torch version : {}\".format(torch.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert images to Batched tensors\n",
    "\n",
    "## Tensors\n",
    "In pytorch tensors are multi-dimensional arrays similar to np arrays, but with additional capabilities for GPU acceleration and automatic differentiation. Tensors are the fundamental building blocks for representing data and parameters in neural networks.\n",
    "\n",
    "## Batches\n",
    "\n",
    "Batching is a technique here multiple data samples are grouped togheter into a single tensor. This allows for efficient processing of multiple samples simultaneously to take advantage of the parallel processing capabilities of a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_0_color = cv2.imread(\"images/mnist_0.jpg\")\n",
    "digit_1_color = cv2.imread(\"images/mnist_1.jpg\")\n",
    "\n",
    "digit_0_gray = cv2.imread(\"images/mnist_0.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "digit_1_gray = cv2.imread(\"images/mnist_1.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
    "\n",
    "axs[0].imshow(digit_0_color, cmap='gray', interpolation='none')\n",
    "axs[0].set_title(\"Digit 0 Image color\")\n",
    "axs[0].axis('off')\n",
    "\n",
    "\n",
    "axs[1].imshow(digit_1_color, cmap='gray', interpolation='none')\n",
    "axs[1].set_title(\"Digit 1 Image color\")\n",
    "axs[1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#its a np array with 3 channels\n",
    "print(\"Image array shape:\", digit_0_color.shape)\n",
    "print(f\"Min pixel value:{np.min(digit_0_color)} ; Max pixel value : {np.max(digit_0_color)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#its a np.ndarray\n",
    "digit_0_gray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert this Numpy Array (image) to Torch tensors (tensor is a fancy name for matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting and normalizing, 256 rgb values (0-255), so we are normalizing that with 255.0\n",
    "img_0_tensor = torch.tensor(digit_0_color, dtype=torch.float32) / 255.0\n",
    "img_1_tensor = torch.tensor(digit_1_color, dtype=torch.float32) / 255.0\n",
    "\n",
    "print(\"Shape of Normalised Digit 0 Tensor: \", img_0_tensor.shape)\n",
    "print(f\"Normalised Min pixel value: {torch.min(img_0_tensor)} ; Normalised Max pixel value : {torch.max(img_0_tensor)}\")\n",
    "\n",
    "plt.imshow(img_0_tensor,cmap=\"gray\")\n",
    "plt.title(\"Normalised Digit 0 Image\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create input batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_tensor = torch.stack([img_0_tensor, img_1_tensor]) #2 images batched (put togheter)\n",
    "\n",
    "print(\"Batch Tensor Shape:\", batch_tensor.shape)\n",
    "\n",
    "#in PyTorch, image tensors typically follow the shape convention [N ,C ,H ,W] unlike tensorflow which follows [N, H, W, C].\n",
    "#[N ,C ,H ,W] = Batch, Number of Channels, Height, Width\n",
    "#we need to bring the color channel to the second dimension\n",
    "\n",
    "batch_input = batch_tensor.permute(0,3,1,2)\n",
    "print(\"Batch Tensor Shape:\", batch_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_visual = cv2.imread(\"images/tensor_img.png\")\n",
    "plt.imshow(tensor_visual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct my own tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(5)\n",
    "print(\"a:\",a)\n",
    "\n",
    "b = torch.zeros(5)\n",
    "print(\"b:\",b)\n",
    "\n",
    "c = torch.tensor([1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "print(\"c:\",c)\n",
    "\n",
    "d = torch.zeros(3,2)\n",
    "print(\"d\",d)\n",
    "\n",
    "e = torch.ones(3,2)\n",
    "print(\"e\",e)\n",
    "\n",
    "f = torch.tensor([[1.0, 2.0],[3.0, 4.0]])\n",
    "print(\"f:\",f)\n",
    "\n",
    "#3D Tensor\n",
    "g = torch.tensor([[[1., 2.], [3., 4.]], [[5., 6.], [7., 8.]]])\n",
    "print(\"g:\",g)\n",
    "\n",
    "print(f.shape)\n",
    "\n",
    "print(e.shape)\n",
    "\n",
    "print(g.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access elements in a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get element at index 2\n",
    "print(c[2])\n",
    "\n",
    "# All indices starting from 0\n",
    "\n",
    "# Get element at row 1, column 0\n",
    "print(f[1,0])\n",
    "\n",
    "# We can also use the following\n",
    "print(f[1][0])\n",
    "\n",
    "# Similarly for 3D Tensor\n",
    "print(g[1,0,0])\n",
    "print(g[1][0][0])\n",
    "# All elements\n",
    "print(f[:])\n",
    "\n",
    "# All elements from index 1 to 2 (excluding element 3)\n",
    "print(c[1:3])\n",
    "\n",
    "# All elements till index 4 (exclusive)\n",
    "print(c[:4])\n",
    "\n",
    "# First row all columns\n",
    "print(f[0, :])\n",
    "\n",
    "# Second column all rows just like numpy\n",
    "print(f[:,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_tensor = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(int_tensor.dtype)\n",
    "\n",
    "# What if we changed any one element to floating point number?\n",
    "int_tensor = torch.tensor([[1,2,3],[4.,5,6]])\n",
    "print(int_tensor.dtype)\n",
    "print(int_tensor)\n",
    "\n",
    "# This can be overridden as follows\n",
    "float_tensor = torch.tensor([[1, 2, 3],[4., 5, 6]])\n",
    "int_tensor = float_tensor.type(torch.int64)\n",
    "print(int_tensor.dtype)\n",
    "print(int_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Tensor to/from numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor to Array\n",
    "f_numpy = f.numpy() #here we convert array f from above\n",
    "print(f_numpy)\n",
    "print(f)\n",
    "\n",
    "# Array to Tensor\n",
    "h = np.array([[8,7,6,5],[4,3,2,1]])\n",
    "print(h)\n",
    "h_tensor = torch.from_numpy(h)\n",
    "print(h_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arithmetic Operations on tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1 = torch.tensor([[1,2,3],[4,5,6]])\n",
    "tensor2 = torch.tensor([[-1,2,-3],[4,-5,6]])\n",
    "\n",
    "# Addition\n",
    "print(tensor1+tensor2)\n",
    "# or use this\n",
    "print(torch.add(tensor1,tensor2))\n",
    "\n",
    "# Subtraction\n",
    "print(tensor1-tensor2)\n",
    "# or use this\n",
    "print(torch.sub(tensor1,tensor2))\n",
    "\n",
    "# Multiplication\n",
    "# Tensor with Scalar\n",
    "print(tensor1 * 2)\n",
    "\n",
    "# Tensor with another tensor\n",
    "# Elementwise Multiplication\n",
    "print(tensor1 * tensor2)\n",
    "\n",
    "# Matrix multiplication\n",
    "tensor3 = torch.tensor([[1,2],[3,4],[5,6]])\n",
    "print(torch.mm(tensor1,tensor3))\n",
    "\n",
    "# Division\n",
    "# Tensor with scalar\n",
    "print(tensor1/2)\n",
    "\n",
    "# Tensor with another tensor\n",
    "# Elementwise division\n",
    "print(tensor1/tensor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4])\n",
    "\n",
    "# adding a scalar to a vector\n",
    "result = a + b\n",
    "\n",
    "print(\"Result of Broadcasting:\\n\",result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Broadcasting\n",
    "https://pytorch.org/docs/stable/notes/broadcasting.html#broadcasting-semantics\n",
    "Broadcasting allows PyTorch to perform element-wise operations on tensors of\n",
    "\n",
    "    a is a 2-dimensional tensor with shape ([1, 3]).\n",
    "\n",
    "    b is a 2-dimensional tensor with shape ([3, 1]).\n",
    "\n",
    "    When adding a and b, PyTorch broadcasts both tensors to the common shape ([3, 3]), resulting in:\n",
    "\n",
    "    ⎡1+4 2+4 3+4⎤\n",
    "    ⎢1+5 2+5 3+5⎥\n",
    "    ⎣1+6 2+6 3+6⎦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1, 2, 3]])\n",
    "b = torch.tensor([[4], [5], [6]])\n",
    "\n",
    "# adding tensors of different shapes\n",
    "result = a + b\n",
    "print(\"Shape: \", result.shape)\n",
    "print(\"\\n\")\n",
    "print(\"Result of Broadcasting:\\n\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run on CPU or GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a tensor for CPU\n",
    "#this will occupy CPU RAM\n",
    "tensor_cpu = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]], device='cpu')\n",
    "\n",
    "#create a tensor for GPU\n",
    "#this will occupy GPU RAM\n",
    "tensor_gpu = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]], device='cuda')\n",
    "\n",
    "#this uses CPU RAM\n",
    "tensor_cpu = tensor_cpu * 5\n",
    "\n",
    "#this uses GPU RAM\n",
    "#focus on GPU RAM Consumption\n",
    "tensor_gpu = tensor_gpu * 5\n",
    "\n",
    "#move GPU tensor to CPU\n",
    "tensor_gpu_cpu = tensor_gpu.to(device='cpu')\n",
    "\n",
    "#move CPU tensor to GPU\n",
    "tensor_cpu_gpu = tensor_cpu.to(device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd and Backpropagation\n",
    "\n",
    "torch.autograd allows for automatic differentiation and can be use for backwards propagation, makes it easy.\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#a-gentle-introduction-to-torch-autograd\n",
    "\n",
    "lets say we have z = x*y + y²\n",
    "\n",
    "dz/dx = y\n",
    "dz/dy = x + 2y\n",
    "\n",
    "given x = 2\n",
    "and y = 3\n",
    "\n",
    "gradient of z w.r.t x is: 3\n",
    "\n",
    "gradient of z w.r.t y is: 2 + 2*3 = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensors with requires_grad=True\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "y = torch.tensor([3.0], requires_grad=True)\n",
    "\n",
    "# Perform some operations\n",
    "z = x * y + y**2\n",
    "\n",
    "z.retain_grad() #By default intermediate layer weight updation is not shown.\n",
    "\n",
    "#Compute the gradients\n",
    "z_sum = z.backward()\n",
    "\n",
    "print(f\"Gradient of x: {x.grad}\")\n",
    "print(f\"Gradient of y: {y.grad}\")\n",
    "print(f\"Gradient of z: {z.grad}\")\n",
    "print(f\"Result of the operation: z = {z.detach()}\")\n",
    "\n",
    "x1 = torch.tensor([2.0, 5.0], requires_grad=True) #this is basically weights between neurons in a neural network, imagine weight between input -> neuron layer -> output\n",
    "y1 = torch.tensor([3.0, 7.0], requires_grad=True)\n",
    "\n",
    "# Perform some operations\n",
    "z1 = x1 * y1 + y1**2\n",
    "\n",
    "z1.retain_grad() #By default intermediate layer weight updation is not shown.\n",
    "\n",
    "#Compute the gradients\n",
    "z_sum1 = z1.sum().backward()  #backward expects a scalar (single element tensor by default)\n",
    "                              #here sum HAS to be used, if the tensor has more than one element a runtime error occurs\n",
    "\n",
    "print(f\"Gradient of x: {x1.grad}\")\n",
    "print(f\"Gradient of y: {y1.grad}\")\n",
    "print(f\"Gradient of z: {z1.grad}\")\n",
    "print(f\"Result of the operation: z = {z1.detach()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "# Visualize the computation graph\n",
    "dot = make_dot(z, params={\"x\": x, \"y\": y, \"z\" : z})\n",
    "dot.render(\"grad_computation_graph\", format=\"png\")\n",
    "\n",
    "dot = make_dot(z1, params={\"x\": x1, \"y\": y1, \"z\" : z1})\n",
    "dot.render(\"grad_computation_graph1\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread(\"grad_computation_graph.png\")\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "img = plt.imread(\"grad_computation_graph1.png\")\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "#the number below x,y,z is the amount of numbers in the tensor, 1 in the first case, 2 in the second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detach Tensors from Computation Graph\n",
    "\n",
    "detach() method is used to create a new tensor that shares storage with the original tensor but without tracking its operations. When calling detach() it returns a new tensor that does not require gradients. Useful wehen you want to perform operations on a tnesor without affecting the computation graph.\n",
    "\n",
    "Back propagation cannot be done when requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detach z from the computation graph\n",
    "print(\"Before detaching z from computation: \", z.requires_grad)\n",
    "z_det = z.detach() #returns a new tensor that does not require gradients\n",
    "print(\"After detaching z from computation: \", z_det.requires_grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
